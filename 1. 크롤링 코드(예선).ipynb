{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e1afc27",
   "metadata": {},
   "source": [
    "# Round 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "kL34cihdqcyE",
   "metadata": {
    "id": "kL34cihdqcyE"
   },
   "outputs": [],
   "source": [
    "PATH = 'NHIS_BDC_2023/Round1/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "10c5e062",
   "metadata": {
    "id": "10c5e062"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting py7zr\n",
      "  Downloading py7zr-0.20.8-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting texttable (from py7zr)\n",
      "  Downloading texttable-1.7.0-py2.py3-none-any.whl.metadata (9.8 kB)\n",
      "Collecting pycryptodomex>=3.16.0 (from py7zr)\n",
      "  Downloading pycryptodomex-3.19.0-cp35-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.4 kB)\n",
      "Collecting pyzstd>=0.15.9 (from py7zr)\n",
      "  Downloading pyzstd-0.15.9-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.5 kB)\n",
      "INFO: pip is looking at multiple versions of py7zr to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting py7zr\n",
      "  Downloading py7zr-0.20.7-py3-none-any.whl.metadata (16 kB)\n",
      "  Downloading py7zr-0.20.6-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting pyppmd<1.1.0,>=0.18.1 (from py7zr)\n",
      "  Downloading pyppmd-1.0.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (138 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.6/138.6 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting pybcj>=0.6.0 (from py7zr)\n",
      "  Downloading pybcj-1.0.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (50 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.5/50.5 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting multivolumefile>=0.2.3 (from py7zr)\n",
      "  Downloading multivolumefile-0.2.3-py3-none-any.whl (17 kB)\n",
      "Collecting brotli>=1.0.9 (from py7zr)\n",
      "  Downloading Brotli-1.1.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl.metadata (5.5 kB)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from py7zr) (4.13.0)\n",
      "Collecting inflate64>=0.3.1 (from py7zr)\n",
      "  Downloading inflate64-0.3.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (93 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.6/93.6 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: psutil in /opt/conda/lib/python3.7/site-packages (from py7zr) (5.9.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->py7zr) (3.8.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->py7zr) (4.2.0)\n",
      "Downloading py7zr-0.20.6-py3-none-any.whl (66 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.7/66.7 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading Brotli-1.1.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (2.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m34.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading pycryptodomex-3.19.0-cp35-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pyzstd-0.15.9-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (410 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 kB\u001b[0m \u001b[31m27.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading texttable-1.7.0-py2.py3-none-any.whl (10 kB)\n",
      "Installing collected packages: texttable, brotli, pyzstd, pyppmd, pycryptodomex, multivolumefile, pybcj, inflate64, py7zr\n",
      "Successfully installed brotli-1.1.0 inflate64-0.3.1 multivolumefile-0.2.3 py7zr-0.20.6 pybcj-1.0.1 pycryptodomex-3.19.0 pyppmd-1.0.0 pyzstd-0.15.9 texttable-1.7.0\n",
      "Collecting newspaper3k\n",
      "  Downloading newspaper3k-0.2.8-py3-none-any.whl (211 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.1/211.1 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: beautifulsoup4>=4.4.1 in /opt/conda/lib/python3.7/site-packages (from newspaper3k) (4.11.1)\n",
      "Requirement already satisfied: Pillow>=3.3.0 in /opt/conda/lib/python3.7/site-packages (from newspaper3k) (9.1.1)\n",
      "Requirement already satisfied: PyYAML>=3.11 in /opt/conda/lib/python3.7/site-packages (from newspaper3k) (6.0)\n",
      "Collecting cssselect>=0.9.2 (from newspaper3k)\n",
      "  Downloading cssselect-1.2.0-py2.py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: lxml>=3.6.0 in /opt/conda/lib/python3.7/site-packages (from newspaper3k) (4.9.3)\n",
      "Requirement already satisfied: nltk>=3.2.1 in /opt/conda/lib/python3.7/site-packages (from newspaper3k) (3.8.1)\n",
      "Requirement already satisfied: requests>=2.10.0 in /opt/conda/lib/python3.7/site-packages (from newspaper3k) (2.31.0)\n",
      "Collecting feedparser>=5.2.1 (from newspaper3k)\n",
      "  Downloading feedparser-6.0.10-py3-none-any.whl (81 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.1/81.1 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting tldextract>=2.0.1 (from newspaper3k)\n",
      "  Downloading tldextract-4.0.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting feedfinder2>=0.0.4 (from newspaper3k)\n",
      "  Downloading feedfinder2-0.0.4.tar.gz (3.3 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting jieba3k>=0.35.1 (from newspaper3k)\n",
      "  Downloading jieba3k-0.35.1.zip (7.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m25.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.5.3 in /opt/conda/lib/python3.7/site-packages (from newspaper3k) (2.8.2)\n",
      "Collecting tinysegmenter==0.3 (from newspaper3k)\n",
      "  Downloading tinysegmenter-0.3.tar.gz (16 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.7/site-packages (from beautifulsoup4>=4.4.1->newspaper3k) (2.3.1)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from feedfinder2>=0.0.4->newspaper3k) (1.16.0)\n",
      "Collecting sgmllib3k (from feedparser>=5.2.1->newspaper3k)\n",
      "  Downloading sgmllib3k-1.0.0.tar.gz (5.8 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: click in /opt/conda/lib/python3.7/site-packages (from nltk>=3.2.1->newspaper3k) (8.1.3)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.7/site-packages (from nltk>=3.2.1->newspaper3k) (1.1.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /opt/conda/lib/python3.7/site-packages (from nltk>=3.2.1->newspaper3k) (2023.10.3)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from nltk>=3.2.1->newspaper3k) (4.64.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.7/site-packages (from requests>=2.10.0->newspaper3k) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests>=2.10.0->newspaper3k) (3.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests>=2.10.0->newspaper3k) (1.26.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests>=2.10.0->newspaper3k) (2022.6.15)\n",
      "Requirement already satisfied: requests-file>=1.4 in /opt/conda/lib/python3.7/site-packages (from tldextract>=2.0.1->newspaper3k) (1.5.1)\n",
      "Requirement already satisfied: filelock>=3.0.8 in /opt/conda/lib/python3.7/site-packages (from tldextract>=2.0.1->newspaper3k) (3.12.2)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from click->nltk>=3.2.1->newspaper3k) (4.13.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->click->nltk>=3.2.1->newspaper3k) (3.8.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->click->nltk>=3.2.1->newspaper3k) (4.2.0)\n",
      "Downloading tldextract-4.0.0-py3-none-any.whl (97 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.5/97.5 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: tinysegmenter, feedfinder2, jieba3k, sgmllib3k\n",
      "  Building wheel for tinysegmenter (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for tinysegmenter: filename=tinysegmenter-0.3-py3-none-any.whl size=13553 sha256=24530abe86ba4d2cf132fd8c00012a013e9156a5739f6e3e62dec22f9097005b\n",
      "  Stored in directory: /home/notebook/.cache/pip/wheels/df/67/41/faca10fa501ca010be41b49d40360c2959e1c4f09bcbfa37fa\n",
      "  Building wheel for feedfinder2 (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for feedfinder2: filename=feedfinder2-0.0.4-py3-none-any.whl size=3357 sha256=abb8f31eb81787431423bcde35577e813f453a31945b3b26bc5b700ca28ebb7e\n",
      "  Stored in directory: /home/notebook/.cache/pip/wheels/7f/d4/8f/6e2ca54744c9d7292d88ddb8d42876bcdab5e6d84a21c10346\n",
      "  Building wheel for jieba3k (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for jieba3k: filename=jieba3k-0.35.1-py3-none-any.whl size=7398404 sha256=f4d879a0e9423e9151e23fd1456f2e12babc2a9a5e1e9e959352f48fba32d9c4\n",
      "  Stored in directory: /home/notebook/.cache/pip/wheels/4c/91/46/3c208287b726df325a5979574324878b679116e4baae1af3c3\n",
      "  Building wheel for sgmllib3k (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sgmllib3k: filename=sgmllib3k-1.0.0-py3-none-any.whl size=6066 sha256=144e130e79a7cf18e83d8d372af51f528f5b41ea9279c5a04ae26b4fcb3b91e6\n",
      "  Stored in directory: /home/notebook/.cache/pip/wheels/73/ad/a4/0dff4a6ef231fc0dfa12ffbac2a36cebfdddfe059f50e019aa\n",
      "Successfully built tinysegmenter feedfinder2 jieba3k sgmllib3k\n",
      "Installing collected packages: tinysegmenter, sgmllib3k, jieba3k, feedparser, cssselect, feedfinder2, tldextract, newspaper3k\n",
      "Successfully installed cssselect-1.2.0 feedfinder2-0.0.4 feedparser-6.0.10 jieba3k-0.35.1 newspaper3k-0.2.8 sgmllib3k-1.0.0 tinysegmenter-0.3 tldextract-4.0.0\n",
      "Requirement already satisfied: yfinance in /opt/conda/lib/python3.7/site-packages (0.2.31)\n",
      "Requirement already satisfied: pandas>=1.3.0 in /opt/conda/lib/python3.7/site-packages (from yfinance) (1.3.4)\n",
      "Requirement already satisfied: numpy>=1.16.5 in /opt/conda/lib/python3.7/site-packages (from yfinance) (1.21.6)\n",
      "Requirement already satisfied: requests>=2.31 in /opt/conda/lib/python3.7/site-packages (from yfinance) (2.31.0)\n",
      "Requirement already satisfied: multitasking>=0.0.7 in /opt/conda/lib/python3.7/site-packages (from yfinance) (0.0.11)\n",
      "Requirement already satisfied: lxml>=4.9.1 in /opt/conda/lib/python3.7/site-packages (from yfinance) (4.9.3)\n",
      "Requirement already satisfied: appdirs>=1.4.4 in /opt/conda/lib/python3.7/site-packages (from yfinance) (1.4.4)\n",
      "Requirement already satisfied: pytz>=2022.5 in /opt/conda/lib/python3.7/site-packages (from yfinance) (2023.3.post1)\n",
      "Requirement already satisfied: frozendict>=2.3.4 in /opt/conda/lib/python3.7/site-packages (from yfinance) (2.3.8)\n",
      "Requirement already satisfied: peewee>=3.16.2 in /opt/conda/lib/python3.7/site-packages (from yfinance) (3.17.0)\n",
      "Requirement already satisfied: beautifulsoup4>=4.11.1 in /opt/conda/lib/python3.7/site-packages (from yfinance) (4.11.1)\n",
      "Requirement already satisfied: html5lib>=1.1 in /opt/conda/lib/python3.7/site-packages (from yfinance) (1.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.7/site-packages (from beautifulsoup4>=4.11.1->yfinance) (2.3.1)\n",
      "Requirement already satisfied: six>=1.9 in /opt/conda/lib/python3.7/site-packages (from html5lib>=1.1->yfinance) (1.16.0)\n",
      "Requirement already satisfied: webencodings in /opt/conda/lib/python3.7/site-packages (from html5lib>=1.1->yfinance) (0.5.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.7/site-packages (from pandas>=1.3.0->yfinance) (2.8.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.7/site-packages (from requests>=2.31->yfinance) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests>=2.31->yfinance) (3.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests>=2.31->yfinance) (1.26.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests>=2.31->yfinance) (2022.6.15)\n"
     ]
    }
   ],
   "source": [
    "!pip install py7zr\n",
    "!pip install newspaper3k\n",
    "!pip install yfinance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d1d1746",
   "metadata": {
    "id": "7d1d1746"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import py7zr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from newspaper import Article\n",
    "\n",
    "import os\n",
    "import time\n",
    "import re\n",
    "import warnings\n",
    "\n",
    "import yfinance as yf\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6131cf65",
   "metadata": {
    "id": "6131cf65"
   },
   "source": [
    "# 1. RSS IFO 전처리 및 본문 크롤링\n",
    "- 제공받은 nasdaq_rss_ifo의 데이터 중 본 분석에 맞도록 전처리 및 본문 크롤링을 실행함\n",
    "- nasdaq_df_wo_text.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3c1a97a",
   "metadata": {
    "id": "d3c1a97a"
   },
   "source": [
    "## 행 필터링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e8a93ad8",
   "metadata": {
    "id": "e8a93ad8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NASDAQ_RSS_IFO_202305.csv\n",
      "NASDAQ_RSS_IFO_202306.csv\n",
      "NASDAQ_RSS_IFO_202307.csv\n",
      "NASDAQ_RSS_IFO_202308.csv\n",
      "NASDAQ_RSS_IFO_202301.csv\n",
      "NASDAQ_RSS_IFO_202302.csv\n",
      "NASDAQ_RSS_IFO_202303.csv\n",
      "NASDAQ_RSS_IFO_202304.csv\n"
     ]
    }
   ],
   "source": [
    "# 모든 CSV 파일을 불러와서 하나의 데이터프레임으로 합치기\n",
    "dfs = []\n",
    "for filename in os.listdir(PATH):\n",
    "    if filename.startswith('NASDAQ_RSS_IFO'):\n",
    "        print(filename)\n",
    "        month_df = pd.read_csv(os.path.join(PATH, filename), encoding='latin1')\n",
    "        dfs.append(month_df)\n",
    "\n",
    "# 모든 데이터프레임을 하나로 합치기\n",
    "df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "# 중복 제거\n",
    "df = df.drop_duplicates(keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "31c2c7ac",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "31c2c7ac",
    "outputId": "db715432-1f0f-4f0e-8d9e-fc8d92ca6e67"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(146914, 8)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape # (146914, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "792262ff",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "792262ff",
    "outputId": "9a60b07a-2aee-48db-a805-cb9600bc2607"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 146914 entries, 0 to 2295463\n",
      "Data columns (total 8 columns):\n",
      " #   Column              Non-Null Count   Dtype \n",
      "---  ------              --------------   ----- \n",
      " 0   rgs_dt              146914 non-null  int64 \n",
      " 1   tck_iem_cd          146914 non-null  object\n",
      " 2   til_ifo             146914 non-null  object\n",
      " 3   ctgy_cfc_ifo        146914 non-null  object\n",
      " 4   mdi_ifo             146914 non-null  object\n",
      " 5   news_smy_ifo        146914 non-null  object\n",
      " 6   rld_ose_iem_tck_cd  146914 non-null  object\n",
      " 7   url_ifo             146914 non-null  object\n",
      "dtypes: int64(1), object(7)\n",
      "memory usage: 10.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4cd90606",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4cd90606",
    "outputId": "013b292a-0fb5-45ca-de0e-687f26881e4e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(146914, 9)\n",
      "(93241, 9)\n",
      "(89022, 9)\n",
      "(89022, 8)\n"
     ]
    }
   ],
   "source": [
    "#url 기준 중복 행 제거\n",
    "df['url_base'] = df['url_ifo'].apply(lambda x: re.sub(r'-0$', '', x))\n",
    "print(df.shape)\n",
    "df.drop_duplicates(subset=['url_ifo'], inplace=True)\n",
    "print(df.shape)\n",
    "df = df[~((df.duplicated(subset='url_base', keep=False)) & (df['url_ifo'].str.endswith('-0')))] #-0 앞까지 중복되면서, -0으로 끝나는 url이 들어간 행 모두 제거\n",
    "print(df.shape)\n",
    "df.drop(columns=['url_base'], inplace=True)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "742c1147",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "742c1147",
    "outputId": "a3b2d268-e6d9-42db-9dd6-97d63674a8b1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(89021, 8)\n",
      "(88769, 8)\n",
      "(88676, 8)\n",
      "(88602, 8)\n"
     ]
    }
   ],
   "source": [
    "#url이 \"_\"인 기사를 삭제함\n",
    "#pre-market, after-hours 관련 기사는 단순히 주가를 나열하는 기사이므로 삭제함\n",
    "\n",
    "df = df[~(df['url_ifo']==\"_\")]\n",
    "print(df.shape)\n",
    "df = df[~df['ctgy_cfc_ifo'].str.contains(\"Pre-Market|After-Hours\")]\n",
    "print(df.shape)\n",
    "df = df[~df['til_ifo'].apply(lambda x: 'Pre-Market' in x)]\n",
    "print(df.shape)\n",
    "df = df[~df['til_ifo'].apply(lambda x: 'After-Hours' in x)]\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2ba06058",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2ba06058",
    "outputId": "7485cf95-678f-43c9-c98e-2d65c6a7f3cd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(88602, 8)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a86c98e",
   "metadata": {
    "id": "5a86c98e"
   },
   "source": [
    "### all_tck_iem_cd 열 생성\n",
    "\n",
    "- 본래 tck_iem_cd 열의 주식을 대상으로 분석을 하려고 했으나, 해당 열이 정확하지 않다고 판단함.\n",
    "- 예를 들어, 'AAPL'은 해당 열에 7, 8월에만 등장하는데, 이는 상식적이지 않음\n",
    "- rld_ose_iem_tck_cd 열에는 'AAPL'이 지속적으로 등장하는 것으로 보아, 두 열의 티커코드를 합친 all_tck_iem_cd 열을 생성하여 이를 활용한 분석을 시행하는 게 적절하다고 판단함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d31a88d9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d31a88d9",
    "outputId": "22100195-2ce2-41db-c3d1-d29c6934b4a3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AAPL이 처음 등장하는 날짜:  20230717\n",
      "AAPL이 마지막으로 등장하는 날짜:  20230831\n"
     ]
    }
   ],
   "source": [
    "print('AAPL이 처음 등장하는 날짜: ', min(df[df['tck_iem_cd']=='AAPL']['rgs_dt']))\n",
    "print('AAPL이 마지막으로 등장하는 날짜: ', max(df[df['tck_iem_cd']=='AAPL']['rgs_dt']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "75505baf",
   "metadata": {
    "id": "75505baf"
   },
   "outputs": [],
   "source": [
    "# 'rld_ose_iem_tck_cd' 열에 있는 티커코드를 ','를 기준으로 분리하여 리스트로 만듦\n",
    "df['rld_ose_iem_tck_cd_lst'] = df['rld_ose_iem_tck_cd'].str.split(',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7d4e6816",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7d4e6816",
    "outputId": "6d5ea8c7-dab8-4448-aac8-7f0224f506ed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20230111\n",
      "20230831\n",
      "937\n"
     ]
    }
   ],
   "source": [
    "print(min(df[df['rld_ose_iem_tck_cd_lst'].apply(lambda x: 'AAPL' in x)]['rgs_dt']))\n",
    "print(max(df[df['rld_ose_iem_tck_cd_lst'].apply(lambda x: 'AAPL' in x)]['rgs_dt']))\n",
    "print(len(df[df['rld_ose_iem_tck_cd_lst'].apply(lambda x: 'AAPL' in x)]['rgs_dt']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "16f197d3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "id": "16f197d3",
    "outputId": "20bbb1d9-9fa3-4081-a031-2c2354efbb9a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rld_ose_iem_tck_cd</th>\n",
       "      <th>rld_ose_iem_tck_cd_lst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CERT,CTMX</td>\n",
       "      <td>[CERT, CTMX]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TSLX,OCN</td>\n",
       "      <td>[TSLX, OCN]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PODD,DKNG,CERT,BITF</td>\n",
       "      <td>[PODD, DKNG, CERT, BITF]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TMCI</td>\n",
       "      <td>[TMCI]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NEO,WING</td>\n",
       "      <td>[NEO, WING]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SLNA</td>\n",
       "      <td>[SLNA]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>OBT,SBNY</td>\n",
       "      <td>[OBT, SBNY]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NCLH,ISPO</td>\n",
       "      <td>[NCLH, ISPO]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NSA,DRH</td>\n",
       "      <td>[NSA, DRH]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>AVDL,AVDL,RMTI,TGTX</td>\n",
       "      <td>[AVDL, AVDL, RMTI, TGTX]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    rld_ose_iem_tck_cd    rld_ose_iem_tck_cd_lst\n",
       "0            CERT,CTMX              [CERT, CTMX]\n",
       "1             TSLX,OCN               [TSLX, OCN]\n",
       "2  PODD,DKNG,CERT,BITF  [PODD, DKNG, CERT, BITF]\n",
       "3                 TMCI                    [TMCI]\n",
       "4             NEO,WING               [NEO, WING]\n",
       "5                 SLNA                    [SLNA]\n",
       "6             OBT,SBNY               [OBT, SBNY]\n",
       "7            NCLH,ISPO              [NCLH, ISPO]\n",
       "8              NSA,DRH                [NSA, DRH]\n",
       "9  AVDL,AVDL,RMTI,TGTX  [AVDL, AVDL, RMTI, TGTX]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['rld_ose_iem_tck_cd', 'rld_ose_iem_tck_cd_lst']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5df863d1",
   "metadata": {
    "id": "5df863d1"
   },
   "outputs": [],
   "source": [
    "#'tck_iem_cd'와 'rld_ose_iem_tck_cd_lst'에 있는 모든 주식코드를 all_tck_iem_cd 열에 합치고, 중복된 티커코드가 여러 번 나타나는 경우 제거함\n",
    "\n",
    "df['all_tck_iem_cd'] = df.apply(lambda row: list(set([row['tck_iem_cd']] + row['rld_ose_iem_tck_cd_lst'])), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1b7ebb05",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "1b7ebb05",
    "outputId": "066da368-5c87-4df7-f4e7-45d7391cef7c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tck_iem_cd</th>\n",
       "      <th>rld_ose_iem_tck_cd</th>\n",
       "      <th>all_tck_iem_cd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CERT</td>\n",
       "      <td>CERT,CTMX</td>\n",
       "      <td>[CERT, CTMX]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OCN</td>\n",
       "      <td>TSLX,OCN</td>\n",
       "      <td>[OCN, TSLX]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CERT</td>\n",
       "      <td>PODD,DKNG,CERT,BITF</td>\n",
       "      <td>[CERT, DKNG, BITF, PODD]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TMCI</td>\n",
       "      <td>TMCI</td>\n",
       "      <td>[TMCI]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NEO</td>\n",
       "      <td>NEO,WING</td>\n",
       "      <td>[WING, NEO]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2295444</th>\n",
       "      <td>ABEV</td>\n",
       "      <td>KDP,KDP,ABEV</td>\n",
       "      <td>[ABEV, KDP]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2295446</th>\n",
       "      <td>FFIV</td>\n",
       "      <td>FFIV</td>\n",
       "      <td>[FFIV]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2295450</th>\n",
       "      <td>EDU</td>\n",
       "      <td>EDU</td>\n",
       "      <td>[EDU]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2295452</th>\n",
       "      <td>TDY</td>\n",
       "      <td>TDY</td>\n",
       "      <td>[TDY]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2295463</th>\n",
       "      <td>SLAB</td>\n",
       "      <td>SLAB</td>\n",
       "      <td>[SLAB]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>88602 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        tck_iem_cd   rld_ose_iem_tck_cd            all_tck_iem_cd\n",
       "0             CERT            CERT,CTMX              [CERT, CTMX]\n",
       "1              OCN             TSLX,OCN               [OCN, TSLX]\n",
       "2             CERT  PODD,DKNG,CERT,BITF  [CERT, DKNG, BITF, PODD]\n",
       "3             TMCI                 TMCI                    [TMCI]\n",
       "4              NEO             NEO,WING               [WING, NEO]\n",
       "...            ...                  ...                       ...\n",
       "2295444       ABEV         KDP,KDP,ABEV               [ABEV, KDP]\n",
       "2295446       FFIV                 FFIV                    [FFIV]\n",
       "2295450        EDU                  EDU                     [EDU]\n",
       "2295452        TDY                  TDY                     [TDY]\n",
       "2295463       SLAB                 SLAB                    [SLAB]\n",
       "\n",
       "[88602 rows x 3 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['tck_iem_cd', 'rld_ose_iem_tck_cd', 'all_tck_iem_cd']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "002a0a1a",
   "metadata": {
    "id": "002a0a1a"
   },
   "outputs": [],
   "source": [
    "df.drop('rld_ose_iem_tck_cd_lst', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3ceb1e00",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3ceb1e00",
    "outputId": "3bda5c4f-0278-4115-bb62-b77cc91590fd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['rgs_dt', 'tck_iem_cd', 'til_ifo', 'ctgy_cfc_ifo', 'mdi_ifo',\n",
       "       'news_smy_ifo', 'rld_ose_iem_tck_cd', 'url_ifo', 'all_tck_iem_cd'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "51d4f59a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "51d4f59a",
    "outputId": "6a2559b1-d932-4c9c-9e29-ff570cd9d914"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(88602, 9)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "13672fce",
   "metadata": {
    "id": "13672fce"
   },
   "outputs": [],
   "source": [
    "df.to_csv(os.path.join(PATH, 'nasdaq_df_wo_text.csv'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e53e9a2f",
   "metadata": {
    "id": "e53e9a2f"
   },
   "source": [
    "## Text Crawling\n",
    "- 제공받은 nasdaq_rss_ifo의 url을 newspaper 라이브러리를 이용해 기사본문을 크롤링함.\n",
    "- nasdaq_final.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "JalgSzhbMJg8",
   "metadata": {
    "id": "JalgSzhbMJg8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: newspaper3k in /opt/conda/lib/python3.7/site-packages (0.2.8)\n",
      "Requirement already satisfied: beautifulsoup4>=4.4.1 in /opt/conda/lib/python3.7/site-packages (from newspaper3k) (4.11.1)\n",
      "Requirement already satisfied: Pillow>=3.3.0 in /opt/conda/lib/python3.7/site-packages (from newspaper3k) (9.1.1)\n",
      "Requirement already satisfied: PyYAML>=3.11 in /opt/conda/lib/python3.7/site-packages (from newspaper3k) (6.0)\n",
      "Requirement already satisfied: cssselect>=0.9.2 in /opt/conda/lib/python3.7/site-packages (from newspaper3k) (1.2.0)\n",
      "Requirement already satisfied: lxml>=3.6.0 in /opt/conda/lib/python3.7/site-packages (from newspaper3k) (4.9.3)\n",
      "Requirement already satisfied: nltk>=3.2.1 in /opt/conda/lib/python3.7/site-packages (from newspaper3k) (3.8.1)\n",
      "Requirement already satisfied: requests>=2.10.0 in /opt/conda/lib/python3.7/site-packages (from newspaper3k) (2.31.0)\n",
      "Requirement already satisfied: feedparser>=5.2.1 in /opt/conda/lib/python3.7/site-packages (from newspaper3k) (6.0.10)\n",
      "Requirement already satisfied: tldextract>=2.0.1 in /opt/conda/lib/python3.7/site-packages (from newspaper3k) (4.0.0)\n",
      "Requirement already satisfied: feedfinder2>=0.0.4 in /opt/conda/lib/python3.7/site-packages (from newspaper3k) (0.0.4)\n",
      "Requirement already satisfied: jieba3k>=0.35.1 in /opt/conda/lib/python3.7/site-packages (from newspaper3k) (0.35.1)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in /opt/conda/lib/python3.7/site-packages (from newspaper3k) (2.8.2)\n",
      "Requirement already satisfied: tinysegmenter==0.3 in /opt/conda/lib/python3.7/site-packages (from newspaper3k) (0.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.7/site-packages (from beautifulsoup4>=4.4.1->newspaper3k) (2.3.1)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from feedfinder2>=0.0.4->newspaper3k) (1.16.0)\n",
      "Requirement already satisfied: sgmllib3k in /opt/conda/lib/python3.7/site-packages (from feedparser>=5.2.1->newspaper3k) (1.0.0)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.7/site-packages (from nltk>=3.2.1->newspaper3k) (8.1.3)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.7/site-packages (from nltk>=3.2.1->newspaper3k) (1.1.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /opt/conda/lib/python3.7/site-packages (from nltk>=3.2.1->newspaper3k) (2023.10.3)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from nltk>=3.2.1->newspaper3k) (4.64.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.7/site-packages (from requests>=2.10.0->newspaper3k) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests>=2.10.0->newspaper3k) (3.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests>=2.10.0->newspaper3k) (1.26.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests>=2.10.0->newspaper3k) (2022.6.15)\n",
      "Requirement already satisfied: requests-file>=1.4 in /opt/conda/lib/python3.7/site-packages (from tldextract>=2.0.1->newspaper3k) (1.5.1)\n",
      "Requirement already satisfied: filelock>=3.0.8 in /opt/conda/lib/python3.7/site-packages (from tldextract>=2.0.1->newspaper3k) (3.12.2)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from click->nltk>=3.2.1->newspaper3k) (4.13.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->click->nltk>=3.2.1->newspaper3k) (3.8.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->click->nltk>=3.2.1->newspaper3k) (4.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install newspaper3k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0eda086d",
   "metadata": {
    "id": "0eda086d"
   },
   "outputs": [],
   "source": [
    "from newspaper import Article\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c378834d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c378834d",
    "outputId": "b555f9ba-9e4d-4f63-e5e0-8cc937445e93"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(88602, 9)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nasdaq_df = pd.read_csv(os.path.join(PATH, 'nasdaq_df_wo_text.csv'))\n",
    "nasdaq_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "50ef131b",
   "metadata": {
    "id": "50ef131b"
   },
   "outputs": [],
   "source": [
    "def extract_text(url):\n",
    "\n",
    "    article = Article(url)\n",
    "    article.download()\n",
    "    article.parse()\n",
    "    text = article.text or 'N/A' #text가 없는 경우 'N/A'로 출력\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5b86786a",
   "metadata": {
    "id": "5b86786a"
   },
   "outputs": [],
   "source": [
    "nasdaq_df['text'] = None  # 'text'열을 None으로 초기화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "37676bae",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "37676bae",
    "outputId": "5f304002-12fe-48ee-82f6-2160d6433800"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88602"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nasdaq_df['text'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c435d1c0",
   "metadata": {
    "id": "c435d1c0"
   },
   "outputs": [],
   "source": [
    "#크롤링 코드\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "def crawl_nasdaq_texts(nasdaq_df, start_index, end_index): #start_index, end_index를 조정하여 여러 번에 나눠서 크롤링할 수 있음\n",
    "    for index, row in nasdaq_df.iterrows():\n",
    "        if index < start_index:\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            url = row['url_ifo']\n",
    "            extracted_text = extract_text(url)\n",
    "            nasdaq_df.at[index, 'text'] = extracted_text\n",
    "\n",
    "        #에러 나는 경우 처리(공백은 try 경우에 포함)\n",
    "        except Exception as e:\n",
    "            print(f\"Error at index {index}: {e}\")\n",
    "\n",
    "        if index % 100 == 0:\n",
    "            print(f\"Processing index {index}\")\n",
    "            display(nasdaq_df.iloc[index-10:index])\n",
    "\n",
    "        #아래 코드는 ckpt를 사용할 경우 주석 제거하시면 됩니다.\n",
    "\n",
    "        # if index % 1000 == 0:\n",
    "        #     folder_path = f'{PATH}'\"/nasdaq_text_crawling_ckpt\"\n",
    "        #     if not os.path.exists(folder_path):\n",
    "        #         os.makedirs(folder_path)\n",
    "        #     nasdaq_df.to_csv(os.path.join(PATH, \"nasdaq_text_crawling_ckpt\", f\"{start_index}_{index}_ckpt.csv\"), index=False)\n",
    "\n",
    "        #index > end_index인 경우 자동으로 제거\n",
    "        if index == end_index:\n",
    "            folder_path = f'{PATH}'\"/nasdaq_text_crawling_ckpt\"\n",
    "            if not os.path.exists(folder_path):\n",
    "                os.makedirs(folder_path)\n",
    "            nasdaq_df.to_csv(os.path.join(PATH, \"nasdaq_text_crawling_ckpt\", f\"{start_index}_{index}_ckpt.csv\"), index=False)\n",
    "            print(f\"{start_index}_{index} 크롤링 완료\")\n",
    "            break\n",
    "\n",
    "    return nasdaq_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "047b29ce",
   "metadata": {
    "id": "047b29ce"
   },
   "outputs": [],
   "source": [
    "result_df = crawl_nasdaq_texts(nasdaq_df, 0, len(nasdaq_df)-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d6fbb7",
   "metadata": {
    "id": "a6d6fbb7"
   },
   "outputs": [],
   "source": [
    "#중복 행 제거\n",
    "result_df.drop_duplicates(inplace=True)\n",
    "result_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b912e6",
   "metadata": {
    "id": "66b912e6"
   },
   "outputs": [],
   "source": [
    "# 'text'로 시작하는 모든 열을 필터링\n",
    "text_columns = [col for col in result_df.columns if col.startswith('text')]\n",
    "print(text_columns)\n",
    "\n",
    "# 해당 열들에서 'NaN'(에러가 난 행)이 아닌 첫 번째 값을 찾는 새로운 열 생성. 모두 'NaN'일 경우, 'NaN'으로 저장\n",
    "result_df['text_not_nan'] = result_df[text_columns].apply(lambda row: next((item for item in row if not pd.isna(item)), np.nan), axis=1)\n",
    "\n",
    "result_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e8f409",
   "metadata": {
    "id": "31e8f409"
   },
   "outputs": [],
   "source": [
    "result_df = result_df[result_df['text_not_nan']!='N/A'] #text_not_nan이 'N/A'가 아닌 행만 필터링(text가 공백인 행)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d78fa31",
   "metadata": {
    "id": "6d78fa31"
   },
   "outputs": [],
   "source": [
    "result_df.isna().sum() #text_not_nan에 null값(error난 행) 있는지 확인."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fbb0980",
   "metadata": {
    "id": "8fbb0980"
   },
   "outputs": [],
   "source": [
    "result_df.drop(text_columns, axis=1, inplace=True) #바로 위에서 정의한 text로 시작하는 열 drop(text_not_nan은 drop 안 됨)\n",
    "\n",
    "result_df.rename(columns={'text_not_nan': 'text'}, inplace=True)\n",
    "\n",
    "result_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "245df5cb",
   "metadata": {
    "id": "245df5cb"
   },
   "outputs": [],
   "source": [
    "#error난 url 다시 크롤링 시도한 후 최종 결과를 nasdaq_final.csv에 저장\n",
    "\n",
    "nan_index_range = result_df[result_df['text'].isna()].index\n",
    "print(\"NaN indices: \", nan_index_range)\n",
    "\n",
    "def recrawl_nasdaq_error_texts(nasdaq_df, start_index=0, end_index=len(df)-1, nan_index_range=None): #원하는 index range에서 nan_index_range 찾을 수 있음\n",
    "    error_url_list = []\n",
    "    for index in nan_index_range:\n",
    "        if index < start_index:\n",
    "            continue\n",
    "\n",
    "        # #end_index를 작게 설정하는 경우 대비. end_index=len(df)-1이라면 필요 없음.\n",
    "        # if index > end_index:\n",
    "        #     nasdaq_df.to_csv(os.path.join(PATH, \"nasdaq_final.csv\"), index=False)\n",
    "        #     print(f\"{start_index}_{end_index} 크롤링 완료\")\n",
    "        #     break\n",
    "\n",
    "\n",
    "        try:\n",
    "            url = nasdaq_df.at[index, 'url_ifo']\n",
    "            extracted_text = extract_text(url)\n",
    "            nasdaq_df.at[index, 'text'] = extracted_text\n",
    "            print(f\"Processing index {index}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error at index {index}: {e}\")\n",
    "            error_url_list.append(url)\n",
    "\n",
    "    #error가 난 url이 있는 행 포함하여 저장\n",
    "    print(\"Number of error urls: \", len(error_url_list))\n",
    "    nasdaq_df.to_csv(os.path.join(PATH, \"nasdaq_final.csv\"), index=False)\n",
    "\n",
    "    return nasdaq_df, error_url_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9982df89",
   "metadata": {
    "id": "9982df89"
   },
   "outputs": [],
   "source": [
    "df, error_url_list = recrawl_nasdaq_error_texts(result_df, nan_index_range=nan_index_range)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb933d89",
   "metadata": {
    "id": "cb933d89"
   },
   "source": [
    "# 2. Stock Description Crawling(현재 작동하지 않는 코드)\n",
    "- 야후파이낸스의 라이브러리를 이용해 기업 설명이 기재된 description을 크롤링함.\n",
    "- 추후 토픽의 키워드와 키워드에 맞는 기업을 연결하기 위함.\n",
    "- stock_description.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "59e0dd46",
   "metadata": {
    "id": "59e0dd46"
   },
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import os\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cb071e39-5b3b-4bbb-80cb-fda6c7a8e3e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NHIS_BDC_2023/Round1/'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bc4fd6a4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "bc4fd6a4",
    "outputId": "b90f258b-a27c-4efb-9da0-1ced0636e033"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>isin_cd</th>\n",
       "      <th>tck_iem_cd</th>\n",
       "      <th>fc_sec_krl_nm</th>\n",
       "      <th>fc_sec_eng_nm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>US00211V1061</td>\n",
       "      <td>AACG</td>\n",
       "      <td>ATA                                           ...</td>\n",
       "      <td>ATA CreatGlo                                  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>US00032Q1040</td>\n",
       "      <td>AADI</td>\n",
       "      <td>Aadi Bioscience                               ...</td>\n",
       "      <td>Aadi Bioscience                               ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>US02376R1023</td>\n",
       "      <td>AAL</td>\n",
       "      <td>아메리칸 에어라인스 그룹                                 ...</td>\n",
       "      <td>American Airline                              ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>US03823U1025</td>\n",
       "      <td>AAOI</td>\n",
       "      <td>어플라이드 옵토일렉트로닉스                                ...</td>\n",
       "      <td>AOI                                           ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>US0003602069</td>\n",
       "      <td>AAON</td>\n",
       "      <td>에이에이온                                         ...</td>\n",
       "      <td>AAON                                          ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2738</th>\n",
       "      <td>US4884452065</td>\n",
       "      <td>ZVRA</td>\n",
       "      <td>Zevra                                         ...</td>\n",
       "      <td>Zevra                                         ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2739</th>\n",
       "      <td>US98987D1028</td>\n",
       "      <td>ZVSA</td>\n",
       "      <td>Zyversa                                       ...</td>\n",
       "      <td>Zyversa                                       ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2740</th>\n",
       "      <td>US98985Y1082</td>\n",
       "      <td>ZYME</td>\n",
       "      <td>Zymeworks                                     ...</td>\n",
       "      <td>Zymeworks                                     ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2741</th>\n",
       "      <td>US98986X1090</td>\n",
       "      <td>ZYNE</td>\n",
       "      <td>자이너바 파마수티컬스                                   ...</td>\n",
       "      <td>Zynerba Pharms                                ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2742</th>\n",
       "      <td>US98986M1036</td>\n",
       "      <td>ZYXI</td>\n",
       "      <td>Zynex                                         ...</td>\n",
       "      <td>Zynex                                         ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2743 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           isin_cd    tck_iem_cd  \\\n",
       "0     US00211V1061  AACG           \n",
       "1     US00032Q1040  AADI           \n",
       "2     US02376R1023  AAL            \n",
       "3     US03823U1025  AAOI           \n",
       "4     US0003602069  AAON           \n",
       "...            ...           ...   \n",
       "2738  US4884452065  ZVRA           \n",
       "2739  US98987D1028  ZVSA           \n",
       "2740  US98985Y1082  ZYME           \n",
       "2741  US98986X1090  ZYNE           \n",
       "2742  US98986M1036  ZYXI           \n",
       "\n",
       "                                          fc_sec_krl_nm  \\\n",
       "0     ATA                                           ...   \n",
       "1     Aadi Bioscience                               ...   \n",
       "2     아메리칸 에어라인스 그룹                                 ...   \n",
       "3     어플라이드 옵토일렉트로닉스                                ...   \n",
       "4     에이에이온                                         ...   \n",
       "...                                                 ...   \n",
       "2738  Zevra                                         ...   \n",
       "2739  Zyversa                                       ...   \n",
       "2740  Zymeworks                                     ...   \n",
       "2741  자이너바 파마수티컬스                                   ...   \n",
       "2742  Zynex                                         ...   \n",
       "\n",
       "                                          fc_sec_eng_nm  \n",
       "0     ATA CreatGlo                                  ...  \n",
       "1     Aadi Bioscience                               ...  \n",
       "2     American Airline                              ...  \n",
       "3     AOI                                           ...  \n",
       "4     AAON                                          ...  \n",
       "...                                                 ...  \n",
       "2738  Zevra                                         ...  \n",
       "2739  Zyversa                                       ...  \n",
       "2740  Zymeworks                                     ...  \n",
       "2741  Zynerba Pharms                                ...  \n",
       "2742  Zynex                                         ...  \n",
       "\n",
       "[2743 rows x 4 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stock = pd.read_csv(os.path.join(PATH, 'NASDAQ_FC_STK_IEM_IFO.csv'), encoding = \"cp949\")\n",
    "stock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f62be175",
   "metadata": {
    "id": "f62be175"
   },
   "outputs": [],
   "source": [
    "# 'tck_iem_cd' 열의 공백 제거\n",
    "stock['tck_iem_cd'] = stock['tck_iem_cd'].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c0c4ae21",
   "metadata": {
    "id": "c0c4ae21"
   },
   "outputs": [],
   "source": [
    "# 종목 티커 코드 리스트\n",
    "tck_iem_cds = list(stock['tck_iem_cd'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "eaa09341",
   "metadata": {
    "id": "eaa09341"
   },
   "outputs": [],
   "source": [
    "# 종목 description 추출\n",
    "def get_stock_descriptions(tck_iem_cds):\n",
    "    descriptions = []\n",
    "\n",
    "    for tck_iem_cd in tck_iem_cds:\n",
    "        try:\n",
    "            # Ticker 객체 생성\n",
    "            ticker = yf.Ticker(tck_iem_cd)\n",
    "\n",
    "            # 종목 정보 가져오기 - 예선 때는 작동했으나 현재 작동하지 않는 코드입니다\n",
    "            stock_info = ticker.info \n",
    "\n",
    "            # 'longBusinessSummary' 키에 해당하는 종목 description 정보 가져오기\n",
    "            description = stock_info.get('longBusinessSummary', None)\n",
    "\n",
    "            # 가져온 정보를 리스트에 추가\n",
    "            descriptions.append(description)\n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching data for {tck_iem_cd}: {str(e)}\")\n",
    "            descriptions.append(None)\n",
    "\n",
    "    data = pd.DataFrame({'tck_iem_cd': tck_iem_cds, 'description': descriptions})\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a2fedf2",
   "metadata": {
    "id": "0a2fedf2",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#데이터프레임 생성\n",
    "stock_description = get_stock_descriptions(tck_iem_cds)\n",
    "\n",
    "stock_description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d7c69e",
   "metadata": {
    "id": "33d7c69e"
   },
   "outputs": [],
   "source": [
    "#결측치 확인\n",
    "stock_description.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a55c5c",
   "metadata": {
    "id": "30a55c5c"
   },
   "outputs": [],
   "source": [
    "#전처리\n",
    "stock_description = stock_description.applymap(lambda x: x.strip() if isinstance(x, str) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b94a3576",
   "metadata": {
    "id": "b94a3576"
   },
   "outputs": [],
   "source": [
    "stock_description.dropna(subset=['description'], inplace=True)\n",
    "stock_description.reset_index(drop=True, inplace=True)\n",
    "stock_description.drop_duplicates(subset=['description'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4eb36f5",
   "metadata": {
    "id": "c4eb36f5"
   },
   "outputs": [],
   "source": [
    "stock_description.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "debb2472",
   "metadata": {
    "id": "debb2472"
   },
   "outputs": [],
   "source": [
    "stock_description.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9d891e8",
   "metadata": {
    "id": "d9d891e8"
   },
   "source": [
    "### 데이터프레임에 영문기업명 추가\n",
    "- 추후 FinBERT로 감성분석 진행시 영문기업명을 기준으로 기사 문단을 추출하기 위함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ea0687",
   "metadata": {
    "id": "d2ea0687"
   },
   "outputs": [],
   "source": [
    "company_name = stock[['tck_iem_cd', 'fc_sec_eng_nm']]\n",
    "company_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4087db11",
   "metadata": {
    "id": "4087db11"
   },
   "outputs": [],
   "source": [
    "# 두 데이터프레임을 tck_iem_cd 열을 기준으로 inner join\n",
    "stock_description_new = pd.merge(stock_description, company_name, how='inner', on='tck_iem_cd')\n",
    "stock_description_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f64314ca",
   "metadata": {
    "id": "f64314ca"
   },
   "outputs": [],
   "source": [
    "stock_description_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5655d0d",
   "metadata": {
    "id": "b5655d0d"
   },
   "outputs": [],
   "source": [
    "stock_description_new.to_csv(os.path.join(PATH, 'stock_description.csv'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7569330b",
   "metadata": {
    "id": "7569330b"
   },
   "source": [
    "# 3. CNBC 기사 url 크롤링\n",
    "- 크롤링 목적 : 토픽모델링 시에 사용할 데이터\n",
    "- 데이터 선정 이유: CNBC는 미국의 경제·금융 뉴스 채널로, CNBC에서 각광받거나 언급량이 많은 토픽은 시장에서 많은 관심을 받고 있는 분야라고 여길 수 있다. 그렇기에 투자 기업을 정하기 전 CNBC를 통해 앞으로 성장 가능성이 있거나 시장의 개입이 이뤄질 것 같은 분야를 먼저 확인하고, 해당 분야에서 투자 가치가 있는 기업을 제공하고자 한다.\n",
    "\n",
    "- 수집 데이터 일자 : 2023.1.1 ~ 2023.8.31\n",
    "\n",
    "- 크롤링 방식 : Google에 \"CNBC\"를 검색하고, 7일 단위(2023.1.1 ~ 2023.1.7, ...)로 필터링을 주어, 해당 주의 모든 기사 url 크롤링\n",
    "\n",
    "- 7일 단위로 필터링한 이유 : 구글 검색 결과의 제한(33페이지)으로 인해 기간을 길게 할 경우, 해당 기간의 기사가 모두 표시되지 않기 때문, 기간을 너무 짧게 할 경우에는 필요없는 기사가 추출됨을 확인했기에 7일이 적절하다고 판단."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36491f1a-cd87-494d-824f-22b0f72ebd59",
   "metadata": {},
   "source": [
    "- all_matching_links_final.pkl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "IWcoot6ocn2v",
   "metadata": {
    "id": "IWcoot6ocn2v"
   },
   "source": [
    "- driver 문제로 <CNBC 기사 url 크롤링> 섹션에서는 가상환경에서 실행하셔야 합니다.\n",
    "- conda create -n NH python=3.8\n",
    "- selenium==4.12.0, pandas==2.0.3, re==2.2.1, bs4==4.12.2, requests==2.31.0, newspaper==0.2.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f9d78462",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f9d78462",
    "outputId": "cae6f91a-5f30-4d6e-ec50-7efbdc87b71f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting selenium\n",
      "  Downloading selenium-4.11.2-py3-none-any.whl.metadata (7.0 kB)\n",
      "Requirement already satisfied: urllib3<3,>=1.26 in /opt/conda/lib/python3.7/site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.26.9)\n",
      "Collecting trio~=0.17 (from selenium)\n",
      "  Downloading trio-0.22.2-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting trio-websocket~=0.9 (from selenium)\n",
      "  Downloading trio_websocket-0.11.1-py3-none-any.whl.metadata (4.7 kB)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in /opt/conda/lib/python3.7/site-packages (from selenium) (2022.6.15)\n",
      "Requirement already satisfied: attrs>=20.1.0 in /opt/conda/lib/python3.7/site-packages (from trio~=0.17->selenium) (21.4.0)\n",
      "Collecting sortedcontainers (from trio~=0.17->selenium)\n",
      "  Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB)\n",
      "Requirement already satisfied: idna in /opt/conda/lib/python3.7/site-packages (from trio~=0.17->selenium) (3.3)\n",
      "Collecting outcome (from trio~=0.17->selenium)\n",
      "  Downloading outcome-1.3.0.post0-py2.py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: sniffio in /opt/conda/lib/python3.7/site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Collecting exceptiongroup>=1.0.0rc9 (from trio~=0.17->selenium)\n",
      "  Downloading exceptiongroup-1.1.3-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting wsproto>=0.14 (from trio-websocket~=0.9->selenium)\n",
      "  Downloading wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in /opt/conda/lib/python3.7/site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
      "Collecting h11<1,>=0.9.0 (from wsproto>=0.14->trio-websocket~=0.9->selenium)\n",
      "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from h11<1,>=0.9.0->wsproto>=0.14->trio-websocket~=0.9->selenium) (4.2.0)\n",
      "Downloading selenium-4.11.2-py3-none-any.whl (7.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m72.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading trio-0.22.2-py3-none-any.whl (400 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m400.2/400.2 kB\u001b[0m \u001b[31m36.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading trio_websocket-0.11.1-py3-none-any.whl (17 kB)\n",
      "Downloading exceptiongroup-1.1.3-py3-none-any.whl (14 kB)\n",
      "Downloading outcome-1.3.0.post0-py2.py3-none-any.whl (10 kB)\n",
      "Installing collected packages: sortedcontainers, outcome, h11, exceptiongroup, wsproto, trio, trio-websocket, selenium\n",
      "Successfully installed exceptiongroup-1.1.3 h11-0.14.0 outcome-1.3.0.post0 selenium-4.11.2 sortedcontainers-2.4.0 trio-0.22.2 trio-websocket-0.11.1 wsproto-1.2.0\n",
      "Requirement already satisfied: bs4 in /opt/conda/lib/python3.7/site-packages (0.0.1)\n",
      "Requirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.7/site-packages (from bs4) (4.11.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.7/site-packages (from beautifulsoup4->bs4) (2.3.1)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (2.31.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.7/site-packages (from requests) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests) (3.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests) (1.26.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests) (2022.6.15)\n",
      "Requirement already satisfied: newspaper3k in /opt/conda/lib/python3.7/site-packages (0.2.8)\n",
      "Requirement already satisfied: beautifulsoup4>=4.4.1 in /opt/conda/lib/python3.7/site-packages (from newspaper3k) (4.11.1)\n",
      "Requirement already satisfied: Pillow>=3.3.0 in /opt/conda/lib/python3.7/site-packages (from newspaper3k) (9.1.1)\n",
      "Requirement already satisfied: PyYAML>=3.11 in /opt/conda/lib/python3.7/site-packages (from newspaper3k) (6.0)\n",
      "Requirement already satisfied: cssselect>=0.9.2 in /opt/conda/lib/python3.7/site-packages (from newspaper3k) (1.2.0)\n",
      "Requirement already satisfied: lxml>=3.6.0 in /opt/conda/lib/python3.7/site-packages (from newspaper3k) (4.9.3)\n",
      "Requirement already satisfied: nltk>=3.2.1 in /opt/conda/lib/python3.7/site-packages (from newspaper3k) (3.8.1)\n",
      "Requirement already satisfied: requests>=2.10.0 in /opt/conda/lib/python3.7/site-packages (from newspaper3k) (2.31.0)\n",
      "Requirement already satisfied: feedparser>=5.2.1 in /opt/conda/lib/python3.7/site-packages (from newspaper3k) (6.0.10)\n",
      "Requirement already satisfied: tldextract>=2.0.1 in /opt/conda/lib/python3.7/site-packages (from newspaper3k) (4.0.0)\n",
      "Requirement already satisfied: feedfinder2>=0.0.4 in /opt/conda/lib/python3.7/site-packages (from newspaper3k) (0.0.4)\n",
      "Requirement already satisfied: jieba3k>=0.35.1 in /opt/conda/lib/python3.7/site-packages (from newspaper3k) (0.35.1)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in /opt/conda/lib/python3.7/site-packages (from newspaper3k) (2.8.2)\n",
      "Requirement already satisfied: tinysegmenter==0.3 in /opt/conda/lib/python3.7/site-packages (from newspaper3k) (0.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.7/site-packages (from beautifulsoup4>=4.4.1->newspaper3k) (2.3.1)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from feedfinder2>=0.0.4->newspaper3k) (1.16.0)\n",
      "Requirement already satisfied: sgmllib3k in /opt/conda/lib/python3.7/site-packages (from feedparser>=5.2.1->newspaper3k) (1.0.0)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.7/site-packages (from nltk>=3.2.1->newspaper3k) (8.1.3)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.7/site-packages (from nltk>=3.2.1->newspaper3k) (1.1.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /opt/conda/lib/python3.7/site-packages (from nltk>=3.2.1->newspaper3k) (2023.10.3)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from nltk>=3.2.1->newspaper3k) (4.64.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.7/site-packages (from requests>=2.10.0->newspaper3k) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests>=2.10.0->newspaper3k) (3.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests>=2.10.0->newspaper3k) (1.26.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests>=2.10.0->newspaper3k) (2022.6.15)\n",
      "Requirement already satisfied: requests-file>=1.4 in /opt/conda/lib/python3.7/site-packages (from tldextract>=2.0.1->newspaper3k) (1.5.1)\n",
      "Requirement already satisfied: filelock>=3.0.8 in /opt/conda/lib/python3.7/site-packages (from tldextract>=2.0.1->newspaper3k) (3.12.2)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from click->nltk>=3.2.1->newspaper3k) (4.13.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->click->nltk>=3.2.1->newspaper3k) (3.8.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->click->nltk>=3.2.1->newspaper3k) (4.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install selenium\n",
    "!pip install bs4\n",
    "!pip install requests\n",
    "!pip install newspaper3k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c08ddd7f",
   "metadata": {
    "id": "c08ddd7f"
   },
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import re\n",
    "from datetime import datetime, timedelta\n",
    "import pickle\n",
    "import os\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from newspaper import Article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "17c4f510",
   "metadata": {
    "id": "17c4f510"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NHIS_BDC_2023/Round1/'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d39c692",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 735
    },
    "id": "4d39c692",
    "outputId": "5094dfb1-4b20-49c8-8ae2-3b2917c07743"
   },
   "outputs": [],
   "source": [
    "chrome_options = webdriver.ChromeOptions()\n",
    "chrome_options.add_argument('--headless')\n",
    "driver = webdriver.Chrome(options=chrome_options)\n",
    "\n",
    "\n",
    "def cnbc_crawling(start_date, end_date):\n",
    "\n",
    "    global driver\n",
    "\n",
    "    start_values_iter = iter(range(0, 320, 10)) #페이지 number - 0이면 10페이지\n",
    "    current_matching_links = []\n",
    "    retry_count = 0\n",
    "    terminate_flag = False\n",
    "\n",
    "    while True:\n",
    "        if terminate_flag:\n",
    "            break\n",
    "\n",
    "        #구글 검색결과의 각 페이지에서 크롤링\n",
    "        try:\n",
    "            current_start = next(start_values_iter)\n",
    "        except StopIteration:\n",
    "            break\n",
    "\n",
    "        print(f\"page: {current_start // 10 + 1}\")\n",
    "\n",
    "        while True:\n",
    "            matching_links_count = 0\n",
    "            date_range_str = f\"cd_min:{start_date},cd_max:{end_date}\"\n",
    "            google_search_url = f'https://www.google.com/search?q=cnbc&sca_esv=568517199&tbs=cdr:1,{date_range_str}&tbm=nws&sxsrf=AM9HkKmYdZ0_zRMPireMpaE6VsIgqW5jBg:1695740222154&ei=PvESZZmECbfh2roPnbOa-A0&start={current_start}&sa=N&ved=2ahUKEwiZm8rMxMiBAxW3sFYBHZ2ZBt84ygIQ8tMDegQIAxAW&biw=1137&bih=790&dpr=2'\n",
    "            driver.get(google_search_url)\n",
    "\n",
    "            links_with_class = driver.find_elements(By.CSS_SELECTOR, 'a.WlydOe[jsname=\"YKoRaf\"]')\n",
    "            for link in links_with_class:\n",
    "                href = link.get_attribute('href')\n",
    "\n",
    "                if href and re.match(r'https://www\\.cnbc\\.com/2023/\\d{2}/\\d{2}/[a-z0-9-]+\\.html', href):\n",
    "                    current_matching_links.append(href)\n",
    "                    print(href)\n",
    "                    matching_links_count += 1\n",
    "\n",
    "            if matching_links_count > 0:\n",
    "                retry_count = 0\n",
    "                break\n",
    "\n",
    "            #해당 페이지에 matching되는 url이 없으면 재시도 - \"로봇이 아닙니다\"가 뜨거나 페이지가 비었다면, matching되는 url이 없을 것\n",
    "            else:\n",
    "                driver.quit()\n",
    "                driver = webdriver.Chrome(options=chrome_options)\n",
    "                retry_count += 1\n",
    "\n",
    "            #재시도 횟수가 2번 이상이면 terminate시키고 다음 기간으로 넘어감. (그 페이지가 비었다는 뜻이므로). 재시도란, 결과가 나오지 않아 드라이버를 껐다 켜는 행위.\n",
    "            #\"로봇이 아닙니다\"는 driver를 새로 열면 사라지므로, 재시도 횟수가 2번 이상이라는 것은 정말 페이지가 비었다는 의미.\n",
    "            if retry_count >= 2:\n",
    "                terminate_flag = True\n",
    "                break\n",
    "\n",
    "    return current_matching_links\n",
    "\n",
    "#함수 호출 예시 - 7일 단위로 날짜 설정해주기\n",
    "cnbc_crawling(\"01/01/2023\", \"01/07/2023\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e067c5",
   "metadata": {
    "id": "24e067c5"
   },
   "outputs": [],
   "source": [
    "#7일 단위로 크롤링\n",
    "\n",
    "start_date = datetime.strptime(\"1/1/2023\", \"%m/%d/%Y\")\n",
    "end_date = datetime.strptime(\"8/31/2023\", \"%m/%d/%Y\")\n",
    "all_matching_links = [] #모든 link 저장\n",
    "empty_count = 0\n",
    "\n",
    "# Driver options\n",
    "chrome_options = webdriver.ChromeOptions()\n",
    "chrome_options.add_argument('--headless')\n",
    "driver = webdriver.Chrome(options=chrome_options)\n",
    "\n",
    "# 7일 범위 날짜 생성\n",
    "while start_date <= end_date:\n",
    "    next_end_date = start_date + timedelta(days=6)\n",
    "    if next_end_date > end_date:\n",
    "        next_end_date = end_date\n",
    "\n",
    "    #7일 단위로 크롤링\n",
    "    current_start_date, current_end_date = (start_date.strftime(\"%m/%d/%Y\"), next_end_date.strftime(\"%m/%d/%Y\"))\n",
    "    current_matching_links = cnbc_crawling(current_start_date, current_end_date)\n",
    "    all_matching_links += current_matching_links\n",
    "\n",
    "    # 결과 처리 또는 저장\n",
    "    print(f'크롤링 결과 (시작 날짜: {current_start_date}, 종료 날짜: {current_end_date}):')\n",
    "    print(f'누적 크롤링된 기사 수: {len(all_matching_links)}')\n",
    "    print(f'현재 크롤링된 기사 수: {len(current_matching_links)}')\n",
    "\n",
    "    start_date += timedelta(days=7)\n",
    "\n",
    "\n",
    "    # ###4주마다 체크포인트 저장\n",
    "    # week_counter += 1  # Increment week_counter\n",
    "    # if week_counter == 4:  # Check if 4 weeks have passed\n",
    "    #     file_name = f\"all_matching_links_{next_end_date.strftime('%Y_%m_%d')}.pkl\"\n",
    "    #     full_path = os.path.join(PATH, file_name)\n",
    "    #     with open(full_path, 'wb') as f:\n",
    "    #         pickle.dump(all_matching_links, f)\n",
    "    #     week_counter = 0  # Reset week_counter\n",
    "\n",
    "    # Save the remaining data if next_end_date reaches end_date\n",
    "\n",
    "if next_end_date == end_date:\n",
    "    file_name = \"all_matching_links_final.pkl\"\n",
    "    full_path = os.path.join(PATH, file_name)\n",
    "    with open(full_path, 'wb') as f:\n",
    "            pickle.dump(all_matching_links, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0045703",
   "metadata": {
    "id": "e0045703"
   },
   "source": [
    "## url에 접속하여 기사 정보 크롤링하기\n",
    "\n",
    "- url에 접속하여, 제목, 날짜, 카테고리, Key Points(기사요약), 본문 크롤링\n",
    "- 카테고리 크롤링 이유 : 분석 시, 주식 정보에 관련 없는 카테고리는 삭제하기 위함.\n",
    "- Key Points 크롤링 이유 : 기사 요약본으로 토픽모델링을 진행하고자 했으나, 문자열이 짧아 토픽이 잘 추출되지 않았음.\n",
    "- 본문 크롤링 이유 : 토픽모델링에 실제로 사용한 데이터, 본문 데이터로 토픽모델링을 진행한 결과 토픽이 가장 잘 추출되었음.\n",
    "- cnbc_newsdata_final.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b44885",
   "metadata": {
    "id": "b2b44885"
   },
   "outputs": [],
   "source": [
    "all_matching_links = pd.read_pickle(os.path.join(PATH, \"all_matching_links_final.pkl\"))\n",
    "\n",
    "CNBC_CKPT_PATH = os.path.join(PATH, \"news_info_ckpt\")\n",
    "if not os.path.exists(CNBC_CKPT_PATH):\n",
    "    os.makedirs(CNBC_CKPT_PATH, exist_ok=True)\n",
    "\n",
    "\n",
    "#Key Points 크롤링\n",
    "def extract_key_points(url):\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        target_div = soup.find('div', {'class': 'group'})\n",
    "        if target_div:\n",
    "            ul = target_div.find('ul')\n",
    "            if ul:\n",
    "                lis = ul.find_all('li')\n",
    "                return ' '.join([li.text for li in lis])\n",
    "    except Exception as e:\n",
    "        print(f\"Error in extract_key_points: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "\n",
    "chrome_options = webdriver.ChromeOptions()\n",
    "chrome_options.add_argument('--headless')\n",
    "driver = webdriver.Chrome(options=chrome_options)\n",
    "\n",
    "# 기사의 정보를 저장할 list 생성\n",
    "articles_data = []\n",
    "\n",
    "\n",
    "def extract_article_info(url, retry_count=0): #재시도 횟수 0에서 시작\n",
    "    global driver  # 드라이버를 글로벌 변수로 설정\n",
    "\n",
    "    #category 크롤링\n",
    "    try:\n",
    "        driver.get(url)\n",
    "        page_html = driver.page_source\n",
    "        soup = BeautifulSoup(page_html, 'html.parser')\n",
    "\n",
    "        article_header = soup.find(class_='ArticleHeader-eyebrow') or soup.find(class_='ArticleHeader-styles-makeit-eyebrow--Degp4')\n",
    "\n",
    "        category = article_header.text if article_header else \"N/A\"\n",
    "    except Exception as e:\n",
    "        print(f\"Error in category extraction: {e}\")\n",
    "        category = \"\"\n",
    "\n",
    "\n",
    "    #title, date, key_points, text 크롤링\n",
    "    try:\n",
    "        article = Article(url)\n",
    "        article.download()\n",
    "        article.parse()\n",
    "        title = article.title or 'N/A'\n",
    "        date = article.publish_date or 'N/A'\n",
    "        text = article.text or 'N/A'\n",
    "        key_points = extract_key_points(url) or 'N/A'\n",
    "\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error in newspaper extraction: {e}\")\n",
    "\n",
    "        # 에러가 발생하면 드라이버 재시작\n",
    "        driver.quit()\n",
    "        chrome_options = webdriver.ChromeOptions()\n",
    "        chrome_options.add_argument('--headless')\n",
    "        driver = webdriver.Chrome(options=chrome_options)\n",
    "\n",
    "        # retry_count < 1이면 크롤링 다시 시도\n",
    "        if retry_count < 1:\n",
    "            return extract_article_info(url, retry_count=retry_count + 1) #재귀적 코드\n",
    "\n",
    "        #retry_count >= 1일 때, url을 제외한 행 전체가 빈칸으로 나타남\n",
    "\n",
    "        print(f'Error in {url}')\n",
    "        title, date, text, key_points = \"\", \"\", \"\", \"\"\n",
    "\n",
    "    new_data = {\n",
    "        'title': title,\n",
    "        'date': date,\n",
    "        'category': category,\n",
    "        'key_points': key_points,\n",
    "        'text': text,\n",
    "        'url': url\n",
    "    }\n",
    "\n",
    "    #새로 크롤링한 데이터를 articles_data list에 추가\n",
    "    articles_data.append(new_data)\n",
    "    #print(f\"Newly appended data: {new_data}\")\n",
    "\n",
    "#url list 정의 - link를 날짜 순서대로 정렬\n",
    "url_list = sorted(list(all_matching_links))\n",
    "\n",
    "for idx, url in enumerate(url_list, 1):\n",
    "    extract_article_info(url)\n",
    "\n",
    "    #10개 단위로 체크포인트 파일 저장\n",
    "    if idx % 10 == 0:\n",
    "        checkpoint_df = pd.DataFrame(articles_data)\n",
    "        display(checkpoint_df)\n",
    "\n",
    "        checkpoint_df.to_csv(os.path.join(CNBC_CKPT_PATH, f\"{idx}번째_체크포인트.csv\"), index=False)\n",
    "        print(f\"Saved checkpoint at {idx}th URL.\")\n",
    "\n",
    "    #time.sleep(1.5)\n",
    "\n",
    "driver.quit()\n",
    "\n",
    "df = pd.DataFrame(articles_data)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f883dc4",
   "metadata": {
    "id": "0f883dc4"
   },
   "outputs": [],
   "source": [
    "df[(df=='').any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b6f8c7",
   "metadata": {
    "id": "01b6f8c7"
   },
   "outputs": [],
   "source": [
    "df_filtered = df[df['title'] != '']\n",
    "\n",
    "df_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7536c115-49af-4222-a188-df25f923d3e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered.to_csv(os.path.join(PATH, \"cnbc_newsdata_final.pkl\", index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b926f16",
   "metadata": {
    "id": "5b926f16"
   },
   "outputs": [],
   "source": [
    "# with open(os.path.join(PATH, \"cnbc_newsdata_final.pkl\"), 'wb') as f:\n",
    "#     pickle.dump(df_filtered, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "ff4b1fca65a764b45acb559e482afe389d289dd599b9f8c5fd12ff5c2ea46a65"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
